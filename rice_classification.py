# -*- coding: utf-8 -*-
"""Untitled47.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r_dKx7I4zQaycwUEFlwclV9GSXp6VKGh
"""

import kagglehub
muratkokludataset_rice_image_dataset_path = kagglehub.dataset_download('muratkokludataset/rice-image-dataset')

print('Data source import complete.')

import glob
import os # Import os module

# Create lists of file paths for each class
arborio_files = glob.glob(os.path.join(muratkokludataset_rice_image_dataset_path, 'Rice_Image_Dataset', 'Arborio', '*'))[:1000]
basmati_files = glob.glob(os.path.join(muratkokludataset_rice_image_dataset_path, 'Rice_Image_Dataset', 'Basmati', '*'))[:1000]
ipsala_files = glob.glob(os.path.join(muratkokludataset_rice_image_dataset_path, 'Rice_Image_Dataset', 'Ipsala', '*'))[:1000]
jasmine_files = glob.glob(os.path.join(muratkokludataset_rice_image_dataset_path, 'Rice_Image_Dataset', 'Jasmine', '*'))[:1000]
karacadag_files = glob.glob(os.path.join(muratkokludataset_rice_image_dataset_path, 'Rice_Image_Dataset', 'Karacadag', '*'))[:1000]

print(f"Number of Arborio files: {len(arborio_files)}")
print(f"Number of Basmati files: {len(basmati_files)}")
print(f"Number of Ipsala files: {len(ipsala_files)}")
print(f"Number of Jasmine files: {len(jasmine_files)}")
print(f"Number of Karacadag files: {len(karacadag_files)}")

"""# Task
Complete the project "GrainPalette - A Deep Learning Odyssey In Rice Type Classification Through Transfer Learning" by performing image preprocessing, building and training a deep learning model using transfer learning with MobileNetV2, and saving the trained model. The dataset is already downloaded.

## Image preprocessing

### Subtask:
Import necessary libraries for image manipulation and data handling.

**Reasoning**:
Import the necessary libraries for image manipulation, numerical operations, data splitting, and visualization.
"""

import cv2
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

"""## Image preprocessing

### Subtask:
Define image dimensions for resizing.

**Reasoning**:
Define a variable `image_size` and assign a tuple representing the desired height and width for resizing the images.
"""

image_size = (224, 224)
print(f"Image size defined as: {image_size}")

"""## Image preprocessing

### Subtask:
Create a function to load and resize images.

**Reasoning**:
Define the function `load_and_resize_image` as instructed, using `cv2.imread` to load the image and `cv2.resize` to resize it to the specified `image_size`.
"""

def load_and_resize_image(file_path):
    """Loads and resizes an image.

    Args:
        file_path: The path to the image file.

    Returns:
        The resized image as a NumPy array.
    """
    img = cv2.imread(file_path)
    resized_img = cv2.resize(img, image_size)
    return resized_img

"""## Image preprocessing

### Subtask:
Create a function to link images to their corresponding classes.

**Reasoning**:
Define a function to create image-label pairs from a list of file paths and a class label.
"""

def create_image_label_pairs(file_paths, class_label):
    """Creates a list of image file path and class label pairs.

    Args:
        file_paths: A list of image file paths.
        class_label: The class label for these images.

    Returns:
        A list of tuples, where each tuple contains an image file path and its class label.
    """
    image_label_pairs = []
    for file_path in file_paths:
        image_label_pairs.append((file_path, class_label))
    return image_label_pairs

"""## Image preprocessing

### Subtask:
Apply these functions to the loaded image files.

**Reasoning**:
Apply the defined functions to load and label the image data, then convert the lists to NumPy arrays for further processing.
"""

# Create image-label pairs for each class
arborio_pairs = create_image_label_pairs(arborio_files, 'Arborio')
basmati_pairs = create_image_label_pairs(basmati_files, 'Basmati')
ipsala_pairs = create_image_label_pairs(ipsala_files, 'Ipsala')
jasmine_pairs = create_image_label_pairs(jasmine_files, 'Jasmine')
karacadag_pairs = create_image_label_pairs(karacadag_files, 'Karacadag')

# Concatenate all pairs
all_image_label_pairs = arborio_pairs + basmati_pairs + ipsala_pairs + jasmine_pairs + karacadag_pairs

# Initialize lists for images and labels
images = []
labels = []

# Iterate through pairs, load/resize images, and append to lists
for file_path, label in all_image_label_pairs:
    resized_img = load_and_resize_image(file_path)
    images.append(resized_img)
    labels.append(label)

# Convert lists to NumPy arrays
images_array = np.array(images)
labels_array = np.array(labels)

print("Images and labels loaded and converted to NumPy arrays.")
print(f"Shape of images_array: {images_array.shape}")
print(f"Shape of labels_array: {labels_array.shape}")

"""## Image preprocessing

### Subtask:
Split the data into training, validation, and test sets.

**Reasoning**:
Split the images and labels into training and test sets, then split the training set into training and validation sets, and finally print the shapes of the resulting sets.
"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(images_array, labels_array, test_size=0.2, random_state=42)

# Split the training set further into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 of 0.8 is 0.2

# Print the shapes of the resulting sets
print(f"Shape of X_train: {X_train.shape}")
print(f"Shape of X_val: {X_val.shape}")
print(f"Shape of X_test: {X_test.shape}")
print(f"Shape of y_train: {y_train.shape}")
print(f"Shape of y_val: {y_val.shape}")
print(f"Shape of y_test: {y_test.shape}")

"""## Image preprocessing

### Subtask:
Preview a few images from the dataset.

**Reasoning**:
Select a few images and their corresponding labels from the training set and display them with their labels.
"""

# Select a few images and labels to preview (e.g., 5 images)
num_images_to_preview = 5
selected_indices = np.random.choice(len(X_train), num_images_to_preview, replace=False)
sample_images = X_train[selected_indices]
sample_labels = y_train[selected_indices]

# Create a figure and subplots
plt.figure(figsize=(10, 5))

# Iterate and display images
for i in range(num_images_to_preview):
    plt.subplot(1, num_images_to_preview, i + 1)
    plt.imshow(sample_images[i])
    plt.title(sample_labels[i])
    plt.axis('off') # Hide axes

plt.tight_layout() # Adjust layout
plt.show()

"""## Model building

### Subtask:
Load a pre-trained MobileNetV2 model as a feature extractor.

**Reasoning**:
Load the pre-trained MobileNetV2 model as a feature extractor and make its layers non-trainable.
"""

from tensorflow.keras.applications import MobileNetV2

# Load the MobileNetV2 model with weights='imagenet', exclude the top classification layer,
# and set the input shape to the defined image size with 3 channels.
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))

# Make the layers of the base model non-trainable
base_model.trainable = False

print("MobileNetV2 base model loaded and layers frozen.")

"""## Model building

### Subtask:
Add dense layers on top of the pre-trained model for classification.

**Reasoning**:
Add layers on top of the pre-trained MobileNetV2 model to build the classification head. This involves adding a Global Average Pooling 2D layer, a Dense layer with ReLU activation, a Dropout layer for regularization, and a final Dense layer with softmax activation for the 5 rice classes.
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout

# Determine the number of classes based on the unique labels
num_classes = len(np.unique(labels_array))

# Create a Sequential model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Print the model summary
model.summary()

"""## Model building

### Subtask:
Configure the learning process (compile the model).

**Reasoning**:
Import necessary components for model compilation and compile the model with Adam optimizer, SparseCategoricalCrossentropy loss, and accuracy metric.
"""

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import SparseCategoricalCrossentropy

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss=SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

print("Model compilation complete.")

"""## Model building

### Subtask:
Train the model on the training data.

**Reasoning**:
Train the compiled model using the training and validation data, store the history, and print a confirmation message.
"""

# Train the model
history = model.fit(
    X_train,
    y_train,
    epochs=10, # You can adjust the number of epochs
    validation_data=(X_val, y_val)
)

print("Model training complete.")

"""**Reasoning**:
The error "ValueError: Invalid dtype: str288" indicates that the labels are still in string format, but the model expects numerical labels for training with `SparseCategoricalCrossentropy`. Convert the string labels to numerical labels.


"""

from sklearn.preprocessing import LabelEncoder

# Convert string labels to numerical labels
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_val_encoded = label_encoder.transform(y_val)
y_test_encoded = label_encoder.transform(y_test)

# Train the model with encoded labels
history = model.fit(
    X_train,
    y_train_encoded,
    epochs=10, # You can adjust the number of epochs
    validation_data=(X_val, y_val_encoded)
)

print("Model training complete.")

# prompt: what is next step do it

# Evaluate the model on the test data
loss, accuracy = model.evaluate(X_test, y_test_encoded)

print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")

# prompt: save the model

# Save the trained model
model.save('rice_classifier.h5')

print("Model saved successfully.")

# prompt: use that model to check classify image

import tensorflow as tf
import numpy as np
import cv2

# Load the trained model
loaded_model = tf.keras.models.load_model('rice_classifier.h5')

# Define the class labels in the order they were encoded
class_labels = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']

def classify_image(image_path, model, label_encoder, image_size):
  """Classifies a single image using the loaded model.

  Args:
    image_path: The path to the image file.
    model: The trained Keras model.
    label_encoder: The fitted LabelEncoder object.
    image_size: The expected input image size (height, width).

  Returns:
    The predicted class label for the image.
  """
  # Load and resize the image
  img = cv2.imread(image_path)
  if img is None:
    print(f"Error: Could not load image from {image_path}")
    return None

  resized_img = cv2.resize(img, (image_size[1], image_size[0])) # OpenCV expects (width, height)
  # Add a batch dimension to the image
  img_array = np.expand_dims(resized_img, axis=0)

  # Make a prediction
  predictions = model.predict(img_array)

  # Get the predicted class index
  predicted_class_index = np.argmax(predictions)

  # Decode the predicted class index back to the original label
  predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]

  return predicted_label

# Example usage: Classify an image (replace 'path/to/your/image.jpg' with the actual image path)
# You would need to have a sample image file available in your Colab environment
# For demonstration, let's use a file path from the downloaded dataset
# Assuming you still have the downloaded dataset path from the previous cells
if 'muratkokludataset_rice_image_dataset_path' in locals():
  sample_image_path = os.path.join(muratkokludataset_rice_image_dataset_path, 'Rice_Image_Dataset', 'Arborio', 'Arborio (1).jpg') # Replace with an actual file path
  predicted_class = classify_image(sample_image_path, loaded_model, label_encoder, image_size)

  if predicted_class:
    print(f"The image at {sample_image_path} is classified as: {predicted_class}")
else:
  print("Dataset path not found. Please ensure the dataset is downloaded and its path variable is accessible.")
  print("Example classification requires a sample image path.")

# If you want to classify another image:
# another_image_path = 'path/to/your/other/image.jpg'
# predicted_class_2 = classify_image(another_image_path, loaded_model, label_encoder, image_size)
# if predicted_class_2:
#   print(f"The image at {another_image_path} is classified as: {predicted_class_2}")

